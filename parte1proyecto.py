# -*- coding: utf-8 -*-
"""parte1Proyecto.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HpM8xVnEYxOcr1u3S6zCIdjNYKsIpUx5
"""

!pip install spacy
!python -m spacy download en_core_web_sm
!pip install scikit-learn

import spacy
import pandas as pd
from spacy.lang.en.stop_words import STOP_WORDS
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.naive_bayes import MultinomialNB
from sklearn.metrics.pairwise import cosine_similarity
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
from sklearn.preprocessing import OneHotEncoder

nlp = spacy.load("en_core_web_sm")

file_path = "/content/Sarcasm_Headlines_Dataset.json"

df = pd.read_json(file_path,lines=True)
df = df.head(100)
def preprocesar_texto(texto):
  tokenizado = nlp(texto.lower())
  tokens = []
  for token in tokenizado:
    if not token.is_stop and not token.is_punct:
      tokens.append(token.lemma_)
  texto_ajustado = ' '.join(tokens)
  return texto_ajustado


df['headline_clean'] = df['headline'].apply(preprocesar_texto)


validacion = df['is_sarcastic'].values

vectorizador = TfidfVectorizer(max_features=1000)
tfid_doc = vectorizador.fit_transform(df['headline_clean']).toarray()

X_train,X_test,Y_train,Y_test = train_test_split(tfid_doc,validacion,test_size=0.2,random_state=42)

regresion = LogisticRegression()
entrenar = regresion.fit(X_train,Y_train)

pred_y = regresion.predict(X_test)

modeloBayes = MultinomialNB()
entrenarBayes = modeloBayes.fit(X_train, Y_train)

y_pred = modeloBayes.predict(X_test)

print(f"Precision:{accuracy_score(Y_test,pred_y)*100:.2f}%")
print(f"Precision Bayes:{accuracy_score(Y_test,y_pred)*100:.2f}%")